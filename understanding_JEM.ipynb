{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding JEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch as t, torch.nn as nn, torch.nn.functional as tnnF, torch.distributions as tdist\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision as tv, torchvision.transforms as tr\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "#import ipdb\n",
    "import numpy as np\n",
    "import wideresnet\n",
    "import json\n",
    "# Sampling\n",
    "from tqdm import tqdm\n",
    "t.backends.cudnn.benchmark = True\n",
    "t.backends.cudnn.enabled = True\n",
    "seed = 1\n",
    "im_sz = 32\n",
    "n_ch = 3\n",
    "\n",
    "# params\n",
    "sigma = 0.03\n",
    "data_root = '../data'\n",
    "n_valid = 5000\n",
    "n_classes = 10\n",
    "labels_per_class = -1\n",
    "batch_size = 64\n",
    "uncond = False\n",
    "reinit_freq = 0.05\n",
    "n_steps = 20\n",
    "sgld_lr = 1.0\n",
    "sgld_std = 0.01\n",
    "dropout_rate = 0.0\n",
    "load_path = None\n",
    "buffer_size = 10000\n",
    "depth = 28\n",
    "width = 10\n",
    "norm  = None\n",
    "lr = 0.0001\n",
    "weight_decay = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSubset(Dataset):\n",
    "    def __init__(self, base_dataset, inds=None, size=-1):\n",
    "        self.base_dataset = base_dataset\n",
    "        if inds is None:\n",
    "            inds = np.random.choice(list(range(len(base_dataset))), size, replace=False)\n",
    "        self.inds = inds\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        base_ind = self.inds[index]\n",
    "        return self.base_dataset[base_ind]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inds)\n",
    "    \n",
    "def cycle(loader):\n",
    "    while True:\n",
    "        for data in loader:\n",
    "            yield data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \n",
    "    transform_train = tr.Compose(\n",
    "        [tr.Pad(4, padding_mode=\"reflect\"),\n",
    "         tr.RandomCrop(im_sz),\n",
    "         tr.RandomHorizontalFlip(),\n",
    "         tr.ToTensor(),\n",
    "         tr.Normalize((.5, .5, .5), (.5, .5, .5)),\n",
    "         lambda x: x + sigma * t.randn_like(x)]\n",
    "    )\n",
    "    transform_test = tr.Compose(\n",
    "        [tr.ToTensor(),\n",
    "         tr.Normalize((.5, .5, .5), (.5, .5, .5)),\n",
    "         lambda x: x + sigma * t.randn_like(x)]\n",
    "    )\n",
    "    def dataset_fn(train, transform):\n",
    "        return tv.datasets.CIFAR10(root=data_root, transform=transform, download=False, train=train)\n",
    "        \n",
    "    # get all training inds\n",
    "    full_train = dataset_fn(True, transform_train)\n",
    "    all_inds = list(range(len(full_train)))\n",
    "    # set seed\n",
    "    np.random.seed(1234)\n",
    "    # shuffle\n",
    "    np.random.shuffle(all_inds)\n",
    "    # seperate out validation set\n",
    "    if n_valid is not None:\n",
    "        valid_inds, train_inds = all_inds[:n_valid], all_inds[n_valid:]\n",
    "    else:\n",
    "        valid_inds, train_inds = [], all_inds\n",
    "    train_inds = np.array(train_inds)\n",
    "    train_labeled_inds = []\n",
    "    other_inds = []\n",
    "    train_labels = np.array([full_train[ind][1] for ind in train_inds])\n",
    "    if labels_per_class > 0:\n",
    "        for i in range(n_classes):\n",
    "            print(i)\n",
    "            train_labeled_inds.extend(train_inds[train_labels == i][:labels_per_class])\n",
    "            other_inds.extend(train_inds[train_labels == i][labels_per_class:])\n",
    "    else:\n",
    "        train_labeled_inds = train_inds\n",
    "        \n",
    "    dset_train = DataSubset(\n",
    "        dataset_fn(True, transform_train),\n",
    "        inds=train_inds)\n",
    "    dset_train_labeled = DataSubset(\n",
    "        dataset_fn(True, transform_train),\n",
    "        inds=train_labeled_inds)\n",
    "    dset_valid = DataSubset(\n",
    "        dataset_fn(True, transform_test),\n",
    "        inds=valid_inds)\n",
    "    dload_train = DataLoader(dset_train, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "    dload_train_labeled = DataLoader(dset_train_labeled, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "    dload_train_labeled = cycle(dload_train_labeled)\n",
    "    dset_test = dataset_fn(False, transform_test)\n",
    "    dload_valid = DataLoader(dset_valid, batch_size=100, shuffle=False, num_workers=4, drop_last=False)\n",
    "    dload_test = DataLoader(dset_test, batch_size=100, shuffle=False, num_workers=4, drop_last=False)\n",
    "    return dload_train, dload_train_labeled, dload_valid,dload_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.manual_seed(seed)\n",
    "if t.cuda.is_available():\n",
    "    t.cuda.manual_seed_all(seed)\n",
    "\n",
    "# datasets\n",
    "\n",
    "dload_train, dload_train_labeled, dload_valid, dload_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = t.device('cuda:2' if t.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_random(bs):\n",
    "    return t.FloatTensor(bs, n_ch, im_sz, im_sz).uniform_(-1, 1)\n",
    "\n",
    "def get_sample_q( device):\n",
    "    def sample_p_0(replay_buffer, bs, y=None):\n",
    "        if len(replay_buffer) == 0:\n",
    "            return init_random(bs), []\n",
    "        buffer_size = len(replay_buffer) if y is None else len(replay_buffer) // n_classes\n",
    "        inds = t.randint(0, buffer_size, (bs,))\n",
    "        # if cond, convert inds to class conditional inds\n",
    "        if y is not None:\n",
    "            inds = y.cpu() * buffer_size + inds\n",
    "            assert not uncond, \"Can't drawn conditional samples without giving me y\"\n",
    "        buffer_samples = replay_buffer[inds]\n",
    "        random_samples = init_random(bs)\n",
    "        choose_random = (t.rand(bs) < reinit_freq).float()[:, None, None, None]\n",
    "        samples = choose_random * random_samples + (1 - choose_random) * buffer_samples\n",
    "        return samples.to(device), inds\n",
    "\n",
    "    def sample_q(f, replay_buffer, y=None, n_steps=n_steps):\n",
    "        \"\"\"this func takes in replay_buffer now so we have the option to sample from\n",
    "        scratch (i.e. replay_buffer==[]).  See test_wrn_ebm.py for example.\n",
    "        \"\"\"\n",
    "        f.eval()\n",
    "        # get batch size\n",
    "        bs = batch_size if y is None else y.size(0)\n",
    "        # generate initial samples and buffer inds of those samples (if buffer is used)\n",
    "        init_sample, buffer_inds = sample_p_0(replay_buffer, bs=bs, y=y)\n",
    "        x_k = t.autograd.Variable(init_sample, requires_grad=True)\n",
    "        # sgld\n",
    "        for k in range(n_steps):\n",
    "            f_prime = t.autograd.grad(f(x_k, y=y).sum(), [x_k], retain_graph=True)[0]\n",
    "            x_k.data += sgld_lr * f_prime + sgld_std * t.randn_like(x_k)\n",
    "        f.train()\n",
    "        final_samples = x_k.detach()\n",
    "        # update replay buffer\n",
    "        if len(replay_buffer) > 0:\n",
    "            replay_buffer[buffer_inds] = final_samples.cpu()\n",
    "        return final_samples\n",
    "    return sample_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_q = get_sample_q(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_sample_q.<locals>.sample_q(f, replay_buffer, y=None, n_steps=20)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F(nn.Module):\n",
    "    def __init__(self, depth=28, width=2, norm=None, dropout_rate=0.0, n_classes=10):\n",
    "        super(F, self).__init__()\n",
    "        self.f = wideresnet.Wide_ResNet(depth, width, norm=norm, dropout_rate=dropout_rate)\n",
    "        self.energy_output = nn.Linear(self.f.last_dim, 1)\n",
    "        self.class_output = nn.Linear(self.f.last_dim, n_classes)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        penult_z = self.f(x)\n",
    "        return self.energy_output(penult_z).squeeze()\n",
    "\n",
    "    def classify(self, x):\n",
    "        penult_z = self.f(x)\n",
    "        return self.class_output(penult_z).squeeze()\n",
    "\n",
    "\n",
    "class CCF(F):\n",
    "    def __init__(self, depth=28, width=2, norm=None, dropout_rate=0.0, n_classes=10):\n",
    "        super(CCF, self).__init__(depth, width, norm=norm, dropout_rate=dropout_rate, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        logits = self.classify(x)\n",
    "        if y is None:\n",
    "            return logits.logsumexp(1)\n",
    "        else:\n",
    "            return t.gather(logits, 1, y[:, None])\n",
    "\n",
    "def get_model_and_buffer(device, sample_q):\n",
    "    model_cls = F if uncond else CCF\n",
    "    f = model_cls(depth, width, norm, dropout_rate=dropout_rate, n_classes=n_classes)\n",
    "    if not uncond:\n",
    "        assert buffer_size % n_classes == 0, \"Buffer size must be divisible by args.n_classes\"\n",
    "    if load_path is None:\n",
    "        # make replay buffer\n",
    "        replay_buffer = init_random(buffer_size)\n",
    "    else:\n",
    "        print(f\"loading model from {load_path}\")\n",
    "        ckpt_dict = t.load(load_path)\n",
    "        f.load_state_dict(ckpt_dict[\"model_state_dict\"])\n",
    "        replay_buffer = ckpt_dict[\"replay_buffer\"]\n",
    "    f = f.to(device)\n",
    "    return f, replay_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x10\n"
     ]
    }
   ],
   "source": [
    "f, replay_buffer = get_model_and_buffer(device, sample_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt = lambda x: int(t.sqrt(t.Tensor([x])))\n",
    "plot = lambda p, x: tv.utils.save_image(t.clamp(x, -1, 1), p, normalize=True, nrow=sqrt(x.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = t.optim.Adam(f.parameters(), lr=lr, betas=[.9, .999], weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: [0.9, 0.999]\n",
       "    eps: 1e-08\n",
       "    lr: 0.0001\n",
       "    weight_decay: 0.0\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1\n",
    "decay_epochs = [160, 180]\n",
    "warmup_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "tensor(2.3067, device='cuda:2', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "best_valid_acc = 0.0\n",
    "cur_iter = 0\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (x_p_d, _) in tqdm(enumerate(dload_train)):\n",
    "        \n",
    "        # train and test samples\n",
    "        x_p_d = x_p_d.to(device)\n",
    "        x_lab, y_lab = dload_train_labeled.__next__()\n",
    "        x_lab, y_lab = x_lab.to(device), y_lab.to(device)\n",
    "        \n",
    "        L = 0.0\n",
    "        \n",
    "        x_q = sample_q(f, replay_buffer)  # sample from log-sumexp\n",
    "\n",
    "        fp_all = f(x_p_d)\n",
    "        fq_all = f(x_q)\n",
    "        print(fp_all.shape)\n",
    "        fp = fp_all.mean()\n",
    "        fq = fq_all.mean()\n",
    "        print(fp)\n",
    "\n",
    "        l_p_x = -(fp - fq)\n",
    "\n",
    "        L += l_p_x\n",
    "\n",
    "        logits = f.classify(x_lab)\n",
    "        l_p_y_given_x = nn.CrossEntropyLoss()(logits, y_lab)\n",
    " \n",
    "        L += l_p_y_given_x\n",
    "\n",
    "        optim.zero_grad()\n",
    "        L.backward()\n",
    "        optim.step()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replay_buffer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
